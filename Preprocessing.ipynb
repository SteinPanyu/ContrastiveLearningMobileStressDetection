{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Funcs.Utility import  *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partcipants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "PARTICIPANTS = pd.read_csv(PATH_PARTICIPANT).set_index('pcode')\n",
    "\n",
    "PARTICIPANTS.to_csv(os.path.join(PATH_INTERMEDIATE, 'PARTICIPANT_INFO.csv'),index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels (via ESM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "LABELS = pd.read_csv(PATH_ESM).assign(\n",
    "    timestamp=lambda x: pd.to_datetime(x['responseTime'], unit='ms', utc=True).dt.tz_convert(DEFAULT_TZ)\n",
    ").set_index(\n",
    "    ['pcode', 'timestamp']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Non-voluntary response: 3323\n",
      "{'n': 76, 'sum': 3323, 'mean': 43.723684210526315, 'SD': 19.36291898394835, 'med': 43.5, 'range': (3, 83), 'conf.': (39.29906768359284, 48.14830073745979), 'nan_count': 0}\n",
      "# Response from participants with enough responses: 2619\n",
      "{'n': 47, 'sum': 2619, 'mean': 55.723404255319146, 'SD': 13.076201628480542, 'med': 52.0, 'range': (36, 83), 'conf.': (51.88408763344431, 59.56272087719398), 'nan_count': 0}\n",
      "# Participants whose responses to ESM delivery were less then 35\n",
      "pcode\n",
      "P04    34\n",
      "P07    24\n",
      "P11    22\n",
      "P14    11\n",
      "P16    30\n",
      "P17    13\n",
      "P18    32\n",
      "P20    31\n",
      "P22    23\n",
      "P24    10\n",
      "P25    30\n",
      "P29    32\n",
      "P34    22\n",
      "P36    29\n",
      "P37    31\n",
      "P38    33\n",
      "P41    31\n",
      "P43    24\n",
      "P44    23\n",
      "P46     4\n",
      "P54    13\n",
      "P56    31\n",
      "P58    29\n",
      "P62     3\n",
      "P63    34\n",
      "P64    30\n",
      "P68    11\n",
      "P73    31\n",
      "P74    33\n",
      "Name: change, dtype: int64 #participants = 29 / #response = 704\n"
     ]
    }
   ],
   "source": [
    "LABELS_VALID = LABELS.loc[\n",
    "    lambda x: ~x['scheduledTime'].isna(), :\n",
    "]\n",
    "print(f'# Non-voluntary response: {len(LABELS_VALID)}')\n",
    "print(summary(LABELS_VALID.groupby('pcode').count().iloc[:, -1]))\n",
    "\n",
    "excl_pcode = LABELS_VALID.loc[\n",
    "    lambda x: ~x['scheduledTime'].isna()\n",
    "].groupby('pcode').count().iloc[:, -1].loc[lambda y: y < 35]\n",
    "\n",
    "LABELS_VALID = LABELS_VALID.loc[\n",
    "    lambda x:  ~x.index.get_level_values('pcode').isin(excl_pcode.index), :\n",
    "]\n",
    "\n",
    "# LABELS_VALID = LABELS\n",
    "\n",
    "# excl_pcode = LABELS_VALID.groupby('pcode').count().iloc[:, -1].loc[lambda y: y < 35]\n",
    "\n",
    "# LABELS_VALID = LABELS_VALID.loc[\n",
    "#     lambda x:  ~x.index.get_level_values('pcode').isin(excl_pcode.index), :\n",
    "# ]\n",
    "\n",
    "print(f'# Response from participants with enough responses: {len(LABELS_VALID)}')\n",
    "print(summary(LABELS_VALID.groupby('pcode').count().iloc[:, -1]))\n",
    "\n",
    "print('# Participants whose responses to ESM delivery were less then 35')\n",
    "print(excl_pcode, f'#participants = {len(excl_pcode)} / #response = {sum(excl_pcode)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop duplicate responses\n",
    "LABELS_VALID = LABELS_VALID.groupby('pcode').apply(lambda x: x.reset_index(drop=False).drop_duplicates(subset='timestamp', keep='first')).set_index(\n",
    "    ['pcode', 'timestamp']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>responseTime</th>\n",
       "      <th>scheduledTime</th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "      <th>attention</th>\n",
       "      <th>stress</th>\n",
       "      <th>duration</th>\n",
       "      <th>disturbance</th>\n",
       "      <th>change</th>\n",
       "      <th>valence_fixed</th>\n",
       "      <th>arousal_fixed</th>\n",
       "      <th>stress_fixed</th>\n",
       "      <th>disturbance_fixed</th>\n",
       "      <th>stress_fixed_tri</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcode</th>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">P01</th>\n",
       "      <th>2019-05-08 10:29:46+09:00</th>\n",
       "      <td>1557278986000</td>\n",
       "      <td>1.557279e+12</td>\n",
       "      <td>-3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-08 11:16:12+09:00</th>\n",
       "      <td>1557281772000</td>\n",
       "      <td>1.557282e+12</td>\n",
       "      <td>-3</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-08 15:58:22+09:00</th>\n",
       "      <td>1557298702000</td>\n",
       "      <td>1.557299e+12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-08 16:41:51+09:00</th>\n",
       "      <td>1557301311000</td>\n",
       "      <td>1.557301e+12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-08 17:27:42+09:00</th>\n",
       "      <td>1557304062000</td>\n",
       "      <td>1.557304e+12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  responseTime  scheduledTime  valence  \\\n",
       "pcode timestamp                                                          \n",
       "P01   2019-05-08 10:29:46+09:00  1557278986000   1.557279e+12       -3   \n",
       "      2019-05-08 11:16:12+09:00  1557281772000   1.557282e+12       -3   \n",
       "      2019-05-08 15:58:22+09:00  1557298702000   1.557299e+12        3   \n",
       "      2019-05-08 16:41:51+09:00  1557301311000   1.557301e+12        3   \n",
       "      2019-05-08 17:27:42+09:00  1557304062000   1.557304e+12        3   \n",
       "\n",
       "                                 arousal  attention  stress  duration  \\\n",
       "pcode timestamp                                                         \n",
       "P01   2019-05-08 10:29:46+09:00        3          3       3       5.0   \n",
       "      2019-05-08 11:16:12+09:00       -2          2       2      15.0   \n",
       "      2019-05-08 15:58:22+09:00        3          3      -3      20.0   \n",
       "      2019-05-08 16:41:51+09:00        3          3      -3      30.0   \n",
       "      2019-05-08 17:27:42+09:00        3          3      -3      20.0   \n",
       "\n",
       "                                 disturbance  change  valence_fixed  \\\n",
       "pcode timestamp                                                       \n",
       "P01   2019-05-08 10:29:46+09:00           -1      -3              0   \n",
       "      2019-05-08 11:16:12+09:00            3      -2              0   \n",
       "      2019-05-08 15:58:22+09:00            2       0              1   \n",
       "      2019-05-08 16:41:51+09:00            1       2              1   \n",
       "      2019-05-08 17:27:42+09:00            2       2              1   \n",
       "\n",
       "                                 arousal_fixed  stress_fixed  \\\n",
       "pcode timestamp                                                \n",
       "P01   2019-05-08 10:29:46+09:00              1             1   \n",
       "      2019-05-08 11:16:12+09:00              0             1   \n",
       "      2019-05-08 15:58:22+09:00              1             0   \n",
       "      2019-05-08 16:41:51+09:00              1             0   \n",
       "      2019-05-08 17:27:42+09:00              1             0   \n",
       "\n",
       "                                 disturbance_fixed  stress_fixed_tri  \n",
       "pcode timestamp                                                       \n",
       "P01   2019-05-08 10:29:46+09:00                  0               2.0  \n",
       "      2019-05-08 11:16:12+09:00                  1               2.0  \n",
       "      2019-05-08 15:58:22+09:00                  1               0.0  \n",
       "      2019-05-08 16:41:51+09:00                  1               0.0  \n",
       "      2019-05-08 17:27:42+09:00                  1               0.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "conditions = [\n",
    "    (LABELS_VALID['stress'] < 0), \n",
    "    (LABELS_VALID['stress'] == 0), \n",
    "    (LABELS_VALID['stress'] > 0)\n",
    "]\n",
    "\n",
    "choices = [0, 1, 2]  # correspondingly negative, zero and positive\n",
    "\n",
    "LABELS_PROC = LABELS_VALID.assign(\n",
    "    valence_fixed = lambda x: np.where(x['valence'] > 0, 1, 0),\n",
    "    arousal_fixed = lambda x: np.where(x['arousal'] > 0, 1, 0),\n",
    "    stress_fixed = lambda x: np.where(x['stress'] > 0, 1, 0),\n",
    "    disturbance_fixed = lambda x: np.where(x['disturbance'] > 0, 1, 0),   \n",
    "    stress_fixed_tri = np.select(conditions, choices, default=np.nan),\n",
    "\n",
    ")\n",
    "LABELS_PROC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def zscore(col):\n",
    "    mean = col.mean()\n",
    "    std = col.std()\n",
    "    return (col - mean) / std\n",
    "\n",
    "# Calculate the overall mean z-score\n",
    "LABELS_PROC['zscore'] = LABELS_PROC['stress'].transform(zscore)\n",
    "overall_mean_zscore = LABELS_PROC['zscore'].mean()\n",
    "\n",
    "# Binarize using the overall mean z-score\n",
    "LABELS_PROC['stress_user_mean'] = (LABELS_PROC['zscore'] > overall_mean_zscore).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1702\n",
       "1     917\n",
       "Name: stress_fixed, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELS_PROC['stress_fixed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS_PROC = LABELS_PROC[LABELS_PROC['stress_fixed_tri']!=1]\n",
    "# Replace all values of 2 with 1 in the 'stress_fixed_tri' column\n",
    "LABELS_PROC['stress_fixed_tri'] = LABELS_PROC['stress_fixed_tri'].replace(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- valence_fixed: {'n': 2181, 'cardinality': 2, 'value_count': '1:1364, 0:817'}\n",
      "- arousal_fixed: {'n': 2181, 'cardinality': 2, 'value_count': '0:1258, 1:923'}\n",
      "- stress_fixed: {'n': 2181, 'cardinality': 2, 'value_count': '0:1264, 1:917'}\n",
      "- disturbance_fixed: {'n': 2181, 'cardinality': 2, 'value_count': '0:1188, 1:993'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "inst = LABELS_PROC.groupby('pcode').count().iloc[:, -1]\n",
    "sam = np.concatenate([\n",
    "    (LABELS_PROC.loc[(p,), :].index.array - LABELS_PROC.loc[(p,), :].index.array.shift(1)).dropna().total_seconds()\n",
    "    for p in LABELS_PROC.index.get_level_values('pcode').unique()\n",
    "])\n",
    "\n",
    "for c in [c for c in LABELS_PROC.columns if (c.endswith('_dyn') or c.endswith('_fixed'))]:\n",
    "    print(f'- {c}:', summary(LABELS_PROC[c].astype(object)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS_PROC.to_csv(os.path.join(PATH_INTERMEDIATE, 'LABELS_PROC.csv'), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# dir = os.path.join(PATH_INTERMEDIATE, 'labeled_joined')# Get the list of files in the directory\n",
    "# file_list = [file for file in os.listdir(dir) if file.endswith('_labeled.csv')]\n",
    "\n",
    "# # Concatenate the CSV files\n",
    "# dfs = []\n",
    "# for file in file_list:\n",
    "#     file_path = os.path.join(dir, file)\n",
    "#     df = pd.read_csv(file_path)\n",
    "#     dfs.append(df)\n",
    "\n",
    "# concatenated_df = pd.concat(dfs)\n",
    "\n",
    "# # Print the concatenated dataframe\n",
    "# print(concatenated_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenated_df.label.value_counts()/61"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.spatial.distance as dist\n",
    "from typing import Dict, Union\n",
    "import pygeohash as geo\n",
    "from datetime import timedelta\n",
    "from collections import defaultdict  \n",
    "from scipy.signal import medfilt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def trim_outlier(col, threshold=3.0):\n",
    "    \"\"\"\n",
    "    Remove the values in a dataframe column based on the median and the median absolute deviation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    col : pandas.Series\n",
    "        The column to be trimmed.\n",
    "    threshold : float, optional\n",
    "        The threshold for trimming, expressed in units of the Median Absolute Deviation (MAD).\n",
    "        Observations with a distance greater than `threshold` times the MAD value from the median are removed.\n",
    "        Default is 3.0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.Series\n",
    "        The column without outliers.\n",
    "    \"\"\"\n",
    "    median = col.median()\n",
    "    mad = (col - median).abs().median()\n",
    "    threshold_value = threshold * mad\n",
    "    mask = (col > median - threshold_value) & (col < median + threshold_value)\n",
    "    return col[mask]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.spatial.distance as dist\n",
    "from typing import Dict, Union\n",
    "#import pygeohash as geo\n",
    "from sklearn.cluster import DBSCAN\n",
    "from datetime import timedelta\n",
    "from collections import defaultdict\n",
    "from poi import PoiCluster\n",
    "import warnings\n",
    "from pandas.errors import PerformanceWarning\n",
    "import neurokit2 as nk\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.integrate import simps\n",
    "import scipy.signal\n",
    "from typing import Union, Dict\n",
    "\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=PerformanceWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "\n",
    "\n",
    "# AmbientLight.csv\n",
    "def _proc_ambient_light(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    return data['brightness'].astype('float32')\n",
    "    \n",
    "\n",
    "# StepCount.csv\n",
    "def _proc_step_count(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    new_data = []\n",
    "\n",
    "    for pcode in data.index.get_level_values('pcode').unique():\n",
    "        sub = data.loc[(pcode, ), :].sort_index(\n",
    "            axis=0, level='timestamp'\n",
    "        ).assign(\n",
    "            steps=lambda x: (x['totalSteps'] - x['totalSteps'].shift(1)),\n",
    "            pcode=pcode\n",
    "        ).reset_index()\n",
    "        new_data.append(sub)\n",
    "\n",
    "    new_data = pd.concat(new_data, axis=0, ignore_index=True).set_index(\n",
    "        ['pcode', 'timestamp']\n",
    "    )\n",
    "\n",
    "    return new_data['steps'].dropna().astype('float32')\n",
    "    \n",
    "\n",
    "\n",
    "# Acceleration.csv\n",
    "def _proc_acceleration(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    data = data.assign(\n",
    "        mag=lambda x: np.sqrt(np.square(x['x']) + np.square(x['y']) + np.square(x['z']))\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'AXX': data['x'].astype('float32'),\n",
    "        'AXY': data['y'].astype('float32'),\n",
    "        'AXZ': data['z'].astype('float32'),\n",
    "        'MAG': data['mag'].astype('float32')\n",
    "    }\n",
    "\n",
    "# SkinTemperature.csv\n",
    "def _proc_skin_temperature(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    temperature = []\n",
    "    for pcode in data.index.get_level_values('pcode').unique():\n",
    "        v = data.loc[(pcode, ), :].sort_index(axis=0,level='timestamp').assign(pcode=pcode)\n",
    "        v = v.reset_index()\n",
    "        v['temperature'] = trim_outlier(v['temperature'], threshold=3.0)\n",
    "        v= v[~v['temperature'].isnull()]\n",
    "        # Z-score normalize column 'temperature'\n",
    "        v['temperature'] = (v['temperature'] - v['temperature'].mean()) / v['temperature'].std()\n",
    "        temperature.append(v)\n",
    "\n",
    "    temperature = pd.concat(temperature, axis=0, ignore_index=True).set_index(\n",
    "                ['pcode', 'timestamp']\n",
    "            ) \n",
    "    \n",
    "    return temperature['temperature'].astype('float32')\n",
    "\n",
    "\n",
    "# RRI.csv\n",
    "def _proc_rri(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    RRI = []\n",
    "    for pcode in data.index.get_level_values('pcode').unique():\n",
    "        v = data.loc[(pcode, ), :].sort_index(axis=0,level='timestamp').assign(pcode=pcode)\n",
    "        v = v.reset_index()\n",
    "        v['interval'] = trim_outlier(v['interval'], threshold=3.0)\n",
    "        v= v[~v['interval'].isnull()]\n",
    "        # Z-score normalize column 'interval'\n",
    "        v['interval'] = (v['interval'] - v['interval'].mean()) / v['interval'].std()\n",
    "        RRI.append(v)\n",
    "\n",
    "    RRI = pd.concat(RRI, axis=0, ignore_index=True).set_index(\n",
    "                ['pcode', 'timestamp']\n",
    "            ) \n",
    "    return RRI['interval'].astype('float32')\n",
    "\n",
    "\n",
    "\n",
    "# HR.csv\n",
    "def _proc_hr(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    data['bpm'] = data.loc[(data['bpm'] >= 30) | (data['bpm'] <= 220), 'bpm']\n",
    "    data= data[~data['bpm'].isnull()]\n",
    "    HRT = []\n",
    "    for pcode in data.index.get_level_values('pcode').unique():\n",
    "        v = data.loc[(pcode, ), :].sort_index(axis=0,level='timestamp').assign(pcode=pcode)\n",
    "        v = v.reset_index()\n",
    "        v['bpm'] = trim_outlier(v['bpm'], threshold=3.0)\n",
    "        v= v[~v['bpm'].isnull()]\n",
    "        # Z-score normalize column 'bpm'\n",
    "        v['bpm'] = (v['bpm'] - v['bpm'].mean()) / v['bpm'].std()\n",
    "        HRT.append(v)\n",
    "\n",
    "    HRT = pd.concat(HRT, axis=0, ignore_index=True).set_index(\n",
    "                ['pcode', 'timestamp']\n",
    "            ) \n",
    "\n",
    "    return HRT['bpm'].astype('float32')\n",
    "    \n",
    "\n",
    "# # EDA.csv\n",
    "# def _proc_eda(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "#     sampling_rate = 8\n",
    "\n",
    "#     # Apply a median filter with a window size of window_size_sec seconds\n",
    "#     window_size_sec = 5\n",
    "#     window_size = window_size_sec * sampling_rate  # Multiply by the sampling frequency (8 Hz)\n",
    "\n",
    "#    #Make the window size odd if it is even\n",
    "#     if window_size % 2 == 0:\n",
    "#         window_size += 1\n",
    "\n",
    "#     data[\"conductance\"] = 1 / (data[\"resistance\"] / 1000) # divide by 1000 to convert kΩ to Ω\n",
    "#     data['conductance'] =data.loc[(data['conductance'] >= 0.01) & (data['conductance'] <= 100), 'conductance']\n",
    "#     data= data[~data['conductance'].isnull()]\n",
    "\n",
    "\n",
    "#     eda = []\n",
    "#     for pcode in data.index.get_level_values('pcode').unique():\n",
    "#         v = data.loc[(pcode, ), :].sort_index(axis=0,level='timestamp').assign(pcode=pcode)\n",
    "#         v = v.reset_index()\n",
    "\n",
    "#         eda_data = v['conductance'].to_numpy()\n",
    "#         eda_data = medfilt(eda_data, window_size)\n",
    "#         # Reshape to 2D with a single column\n",
    "#         eda_data = eda_data.reshape(-1, 1)\n",
    "# #         eda_data = eda_data.reshape(-1)\n",
    "#         # assuming your data is a numpy array with shape (n_samples, n_features)\n",
    "#         scaler = MinMaxScaler()\n",
    "#         eda_data_scaled = scaler.fit_transform(eda_data)\n",
    "#         eda_data = scaler.inverse_transform(eda_data_scaled).reshape(-1)\n",
    "\n",
    "#         v['conductance'] =eda_data\n",
    "#         v= v[~v['conductance'].isnull()]\n",
    "\n",
    "#         eda.append(v)\n",
    "\n",
    "#     eda = pd.concat(eda, axis=0, ignore_index=True).set_index(\n",
    "#                 ['pcode', 'timestamp']\n",
    "#             ) \n",
    "    \n",
    "    \n",
    "#     return eda['conductance'].astype('float32')\n",
    "\n",
    "\n",
    "\n",
    "def _proc_eda(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    sampling_rate = 8\n",
    "\n",
    "    # Low-pass filter parameters\n",
    "    lowpass_cutoff = 0.05  # cutoff frequency for the low-pass filter in Hz\n",
    "\n",
    "    # Apply a median filter with a window size of window_size_sec seconds\n",
    "    window_size_sec = 5\n",
    "    window_size = window_size_sec * sampling_rate\n",
    "    if window_size % 2 == 0:\n",
    "        window_size += 1\n",
    "\n",
    "    data[\"conductance\"] = 1 / (data[\"resistance\"] / 1000)\n",
    "    data = data.loc[(data['conductance'] >= 0.01) & (data['conductance'] <= 100)]\n",
    "\n",
    "    eda_tonic = []\n",
    "    for pcode in data.index.get_level_values('pcode').unique():\n",
    "        v = data.loc[(pcode, ), :].sort_index(axis=0, level='timestamp').assign(pcode=pcode)\n",
    "        v = v.reset_index()\n",
    "\n",
    "        eda_data = v['conductance'].to_numpy()\n",
    "        eda_data = medfilt(eda_data, window_size)\n",
    "\n",
    "        # Apply low-pass filter\n",
    "        b, a = scipy.signal.butter(N=2, Wn=lowpass_cutoff/(0.5 * sampling_rate), btype='low')\n",
    "        tonic_eda = scipy.signal.filtfilt(b, a, eda_data)\n",
    "\n",
    "        # Scale the data\n",
    "        tonic_eda = tonic_eda.reshape(-1, 1)\n",
    "        scaler = MinMaxScaler()\n",
    "        tonic_eda_scaled = scaler.fit_transform(tonic_eda)\n",
    "        tonic_eda = scaler.inverse_transform(tonic_eda_scaled).reshape(-1)\n",
    "\n",
    "        # Add to the dataframe\n",
    "        v['tonic_conductance'] = tonic_eda\n",
    "        eda_tonic.append(v)\n",
    "\n",
    "    eda_tonic = pd.concat(eda_tonic, axis=0, ignore_index=True).set_index(['pcode', 'timestamp'])\n",
    "    \n",
    "    return eda_tonic['tonic_conductance'].astype('float32')\n",
    "\n",
    "\n",
    "# Distance.csv\n",
    "def _proc_distance(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    new_data = []\n",
    "\n",
    "    for pcode in data.index.get_level_values('pcode').unique():\n",
    "        sub = data.loc[(pcode, ), :].sort_index(\n",
    "            axis=0, level='timestamp'\n",
    "        ).assign(\n",
    "            distance=lambda x: x['totalDistance'] - x['totalDistance'].shift(1),\n",
    "            pcode=pcode\n",
    "        ).reset_index()\n",
    "\n",
    "        new_data.append(sub)\n",
    "\n",
    "    new_data = pd.concat(new_data, axis=0, ignore_index=True).set_index(\n",
    "        ['pcode', 'timestamp']\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'DST': new_data['distance'].dropna().astype('float32'),\n",
    "        # 'MOT': new_data['motionType'].astype('object'),\n",
    "        'PAC': new_data['pace'].astype('float32'),\n",
    "        'SPD': new_data['speed'].astype('float32')\n",
    "    }\n",
    "\n",
    "\n",
    "# Calorie.csv\n",
    "def _proc_calories(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    new_data = []\n",
    "\n",
    "    for pcode in data.index.get_level_values('pcode').unique():\n",
    "        sub = data.loc[(pcode, ), :].sort_index(\n",
    "            axis=0, level='timestamp'\n",
    "        ).assign(\n",
    "            calories=lambda x: x['totalCalories'] - x['totalCalories'].shift(1),\n",
    "            pcode=pcode\n",
    "        ).reset_index()\n",
    "\n",
    "        new_data.append(sub)\n",
    "\n",
    "    new_data = pd.concat(new_data, axis=0, ignore_index=True).set_index(\n",
    "        ['pcode', 'timestamp']\n",
    "    )\n",
    "\n",
    "    return new_data['calories'].dropna().astype('float32')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 14:44:17,884\tINFO worker.py:1612 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8267 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m [23-12-19 14:44:19] Begin to processing data: RRI\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m [23-12-19 14:44:19] Begin to processing data: EDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m /tmp/ipykernel_273876/3462566487.py:84: PerformanceWarning: indexing past lexsort depth may impact performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_process pid=274274)\u001b[0m [23-12-19 14:44:52] Complete processing data: RRI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m /tmp/ipykernel_273876/3462566487.py:188: PerformanceWarning: indexing past lexsort depth may impact performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_process pid=274273)\u001b[0m [23-12-19 14:47:57] Complete processing data: EDA\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "from functools import reduce\n",
    "import warnings\n",
    "from pandas.errors import PerformanceWarning\n",
    "from Funcs.Utility import _load_data\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=PerformanceWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "FUNC_PROC = {\n",
    "    # 'Acceleration': _proc_acceleration,\n",
    "    # 'AmbientLight': _proc_ambient_light,\n",
    "    # 'Calorie': _proc_calories,\n",
    "    # 'Distance': _proc_distance,\n",
    "    'EDA': _proc_eda,\n",
    "    # 'HR': _proc_hr,\n",
    "    'RRI': _proc_rri,\n",
    "    # 'SkinTemperature': _proc_skin_temperature,\n",
    "    # 'StepCount': _proc_step_count\n",
    "}\n",
    "\n",
    "\n",
    "def _process(data_type: str):\n",
    "    log(f'Begin to processing data: {data_type}')\n",
    "    \n",
    "    abbrev = DATA_TYPES[data_type]\n",
    "    data_raw = _load_data(data_type)\n",
    "    data_proc = FUNC_PROC[data_type](data_raw)\n",
    "    result = dict()\n",
    "    \n",
    "    if type(data_proc) is dict:\n",
    "        for k, v in data_proc.items():\n",
    "            result[f'{abbrev}_{k}'] = v\n",
    "    else:\n",
    "        result[abbrev] = data_proc\n",
    "        \n",
    "    log(f'Complete processing data: {data_type}')\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "#with on_ray(num_cpus=6):\n",
    "with on_ray():\n",
    "    jobs = []\n",
    "    \n",
    "    func = ray.remote(_process).remote\n",
    "    \n",
    "    for data_type in DATA_TYPES:\n",
    "        job = func(data_type)\n",
    "        jobs.append(job)\n",
    "\n",
    "    jobs = ray.get(jobs)\n",
    "    jobs = reduce(lambda a, b: {**a, **b}, jobs)\n",
    "    dump(jobs, os.path.join(PATH_INTERMEDIATE, 'proc.pkl'))\n",
    "\n",
    "    del jobs\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sci-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
