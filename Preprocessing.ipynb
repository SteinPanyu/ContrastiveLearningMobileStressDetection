{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Funcs.Utility import  *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partcipants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "PARTICIPANTS = pd.read_csv(PATH_PARTICIPANT).set_index('pcode')\n",
    "\n",
    "PARTICIPANTS.to_csv(os.path.join(PATH_INTERMEDIATE, 'proc', 'PARTICIPANT_INFO.csv'),index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels (via ESM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "LABELS = pd.read_csv(PATH_ESM).assign(\n",
    "    timestamp=lambda x: pd.to_datetime(x['responseTime'], unit='ms', utc=True).dt.tz_convert(DEFAULT_TZ)\n",
    ").set_index(\n",
    "    ['pcode', 'timestamp']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Response from participants with enough responses: 5535\n",
      "{'n': 75, 'sum': 5535, 'mean': 73.8, 'SD': 14.026037563393652, 'med': 74.0, 'range': (42, 110), 'conf.': (70.57290183598661, 77.02709816401338), 'nan_count': 0}\n",
      "# Participants whose responses to ESM delivery were less then 35\n",
      "pcode\n",
      "P17    20\n",
      "P22    27\n",
      "Name: change, dtype: int64 #participants = 2 / #response = 47\n"
     ]
    }
   ],
   "source": [
    "# LABELS_VALID = LABELS.loc[\n",
    "#     lambda x: ~x['scheduledTime'].isna(), :\n",
    "# ]\n",
    "# print(f'# Non-voluntary response: {len(LABELS_VALID)}')\n",
    "# print(summary(LABELS_VALID.groupby('pcode').count().iloc[:, -1]))\n",
    "# LABELS_VALID = LABELS\n",
    "\n",
    "# excl_pcode = LABELS_VALID.loc[\n",
    "#     lambda x: ~x['scheduledTime'].isna()\n",
    "# ].groupby('pcode').count().iloc[:, -1].loc[lambda y: y < 35]\n",
    "\n",
    "LABELS_VALID = LABELS\n",
    "\n",
    "excl_pcode = LABELS_VALID.groupby('pcode').count().iloc[:, -1].loc[lambda y: y < 35]\n",
    "\n",
    "# excl_pcode = LABELS_VALID.loc[\n",
    "#     lambda x: ~x['scheduledTime'].isna()\n",
    "# ].groupby('pcode').count().iloc[:, -1].loc[lambda y: y < 35]\n",
    "\n",
    "LABELS_VALID = LABELS_VALID.loc[\n",
    "    lambda x:  ~x.index.get_level_values('pcode').isin(excl_pcode.index), :\n",
    "]\n",
    "print(f'# Response from participants with enough responses: {len(LABELS_VALID)}')\n",
    "print(summary(LABELS_VALID.groupby('pcode').count().iloc[:, -1]))\n",
    "\n",
    "print('# Participants whose responses to ESM delivery were less then 35')\n",
    "print(excl_pcode, f'#participants = {len(excl_pcode)} / #response = {sum(excl_pcode)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>responseTime</th>\n",
       "      <th>scheduledTime</th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "      <th>attention</th>\n",
       "      <th>stress</th>\n",
       "      <th>duration</th>\n",
       "      <th>disturbance</th>\n",
       "      <th>change</th>\n",
       "      <th>valence_fixed</th>\n",
       "      <th>arousal_fixed</th>\n",
       "      <th>stress_fixed</th>\n",
       "      <th>disturbance_fixed</th>\n",
       "      <th>stress_fixed_tri</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcode</th>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">P01</th>\n",
       "      <th>2019-05-08 10:15:03+09:00</th>\n",
       "      <td>1557278103000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-08 10:29:46+09:00</th>\n",
       "      <td>1557278986000</td>\n",
       "      <td>1.557279e+12</td>\n",
       "      <td>-3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-08 11:16:12+09:00</th>\n",
       "      <td>1557281772000</td>\n",
       "      <td>1.557282e+12</td>\n",
       "      <td>-3</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-08 12:45:38+09:00</th>\n",
       "      <td>1557287138000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-08 13:51:57+09:00</th>\n",
       "      <td>1557291117000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  responseTime  scheduledTime  valence  \\\n",
       "pcode timestamp                                                          \n",
       "P01   2019-05-08 10:15:03+09:00  1557278103000            NaN        0   \n",
       "      2019-05-08 10:29:46+09:00  1557278986000   1.557279e+12       -3   \n",
       "      2019-05-08 11:16:12+09:00  1557281772000   1.557282e+12       -3   \n",
       "      2019-05-08 12:45:38+09:00  1557287138000            NaN        2   \n",
       "      2019-05-08 13:51:57+09:00  1557291117000            NaN        3   \n",
       "\n",
       "                                 arousal  attention  stress  duration  \\\n",
       "pcode timestamp                                                         \n",
       "P01   2019-05-08 10:15:03+09:00        0          0      -1      20.0   \n",
       "      2019-05-08 10:29:46+09:00        3          3       3       5.0   \n",
       "      2019-05-08 11:16:12+09:00       -2          2       2      15.0   \n",
       "      2019-05-08 12:45:38+09:00       -1          2       0      15.0   \n",
       "      2019-05-08 13:51:57+09:00        3          3      -3      20.0   \n",
       "\n",
       "                                 disturbance  change  valence_fixed  \\\n",
       "pcode timestamp                                                       \n",
       "P01   2019-05-08 10:15:03+09:00            3      -2              0   \n",
       "      2019-05-08 10:29:46+09:00           -1      -3              0   \n",
       "      2019-05-08 11:16:12+09:00            3      -2              0   \n",
       "      2019-05-08 12:45:38+09:00            1      -1              1   \n",
       "      2019-05-08 13:51:57+09:00            1       0              1   \n",
       "\n",
       "                                 arousal_fixed  stress_fixed  \\\n",
       "pcode timestamp                                                \n",
       "P01   2019-05-08 10:15:03+09:00              0             0   \n",
       "      2019-05-08 10:29:46+09:00              1             1   \n",
       "      2019-05-08 11:16:12+09:00              0             1   \n",
       "      2019-05-08 12:45:38+09:00              0             0   \n",
       "      2019-05-08 13:51:57+09:00              1             0   \n",
       "\n",
       "                                 disturbance_fixed  stress_fixed_tri  \n",
       "pcode timestamp                                                       \n",
       "P01   2019-05-08 10:15:03+09:00               True               0.0  \n",
       "      2019-05-08 10:29:46+09:00              False               2.0  \n",
       "      2019-05-08 11:16:12+09:00               True               2.0  \n",
       "      2019-05-08 12:45:38+09:00               True               1.0  \n",
       "      2019-05-08 13:51:57+09:00               True               0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "conditions = [\n",
    "    (LABELS_VALID['stress'] < 0), \n",
    "    (LABELS_VALID['stress'] == 0), \n",
    "    (LABELS_VALID['stress'] > 0)\n",
    "]\n",
    "\n",
    "choices = [0, 1, 2]  # correspondingly negative, zero and positive\n",
    "\n",
    "LABELS_PROC = LABELS_VALID.assign(\n",
    "    valence_fixed = lambda x: (x['valence'] > 0).astype(int),\n",
    "    arousal_fixed = lambda x: (x['arousal'] > 0).astype(int),\n",
    "    stress_fixed = lambda x: (x['stress'] > 0).astype(int),\n",
    "    disturbance_fixed = lambda x: (x['disturbance'] > 0),   \n",
    "    stress_fixed_tri = np.select(conditions, choices, default=np.nan),\n",
    "\n",
    ")\n",
    "LABELS_PROC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def zscore(col):\n",
    "    mean = col.mean()\n",
    "    std = col.std()\n",
    "    return (col - mean) / std\n",
    "\n",
    "# Calculate the overall mean z-score\n",
    "LABELS_PROC['zscore'] = LABELS_PROC['stress'].transform(zscore)\n",
    "overall_mean_zscore = LABELS_PROC['zscore'].mean()\n",
    "\n",
    "# Binarize using the overall mean z-score\n",
    "LABELS_PROC['stress_user_mean'] = (LABELS_PROC['zscore'] > overall_mean_zscore).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS_PROC.to_csv(os.path.join(PATH_INTERMEDIATE, 'proc', 'LABELS_PROC.csv'), index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.spatial.distance as dist\n",
    "from typing import Dict, Union\n",
    "import pygeohash as geo\n",
    "from datetime import timedelta\n",
    "from collections import defaultdict  \n",
    "from scipy.signal import medfilt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def trim_outlier(col: pd.Series, threshold=3.0) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Remove the values in a dataframe column based on the median and the median absolute deviation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    col : pandas.Series\n",
    "        The column to be trimmed.\n",
    "    threshold : float, optional\n",
    "        The threshold for trimming, expressed in units of the Median Absolute Deviation (MAD).\n",
    "        Observations with a distance greater than `threshold` times the MAD value from the median are removed.\n",
    "        Default is 3.0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.Series\n",
    "        The column without outliers.\n",
    "    \"\"\"\n",
    "    median = col.median()\n",
    "    mad = (col - median).abs().median()\n",
    "    threshold_value = threshold * mad\n",
    "    mask = (col > median - threshold_value) & (col < median + threshold_value)\n",
    "\n",
    "    return col[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.spatial.distance as dist\n",
    "from typing import Dict, Union\n",
    "#import pygeohash as geo\n",
    "from sklearn.cluster import DBSCAN\n",
    "from datetime import timedelta\n",
    "from collections import defaultdict\n",
    "#from poi import PoiCluster\n",
    "from Funcs.Utility import transform\n",
    "import warnings\n",
    "from pandas.errors import PerformanceWarning\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=PerformanceWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "\n",
    "\n",
    "# AmbientLight.csv\n",
    "def _proc_ambient_light(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    return data['brightness'].astype('float32')\n",
    "    \n",
    "\n",
    "# StepCount.csv\n",
    "def _proc_step_count(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    new_data = []\n",
    "\n",
    "    for pcode in data.index.get_level_values('pcode').unique():\n",
    "        sub = data.loc[(pcode, ), :].sort_index(\n",
    "            axis=0, level='timestamp'\n",
    "        ).assign(\n",
    "            steps=lambda x: (x['totalSteps'] - x['totalSteps'].shift(1)),\n",
    "            pcode=pcode\n",
    "        ).reset_index()\n",
    "        new_data.append(sub)\n",
    "\n",
    "    new_data = pd.concat(new_data, axis=0, ignore_index=True).set_index(\n",
    "        ['pcode', 'timestamp']\n",
    "    )\n",
    "\n",
    "    return new_data['steps'].dropna().astype('float32')\n",
    "    \n",
    "\n",
    "\n",
    "# Acceleration.csv\n",
    "def _proc_acceleration(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    data = data.assign(\n",
    "        mag=lambda x: np.sqrt(np.square(x['x']) + np.square(x['y']) + np.square(x['z']))\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'AXX': data['x'].astype('float32'),\n",
    "        'AXY': data['y'].astype('float32'),\n",
    "        'AXZ': data['z'].astype('float32'),\n",
    "        'MAG': data['mag'].astype('float32')\n",
    "    }\n",
    "\n",
    "# SkinTemperature.csv\n",
    "def _proc_skin_temperature(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    temperature = []\n",
    "    for pcode in data.index.get_level_values('pcode').unique():\n",
    "        v = data.loc[(pcode, ), :].sort_index(axis=0,level='timestamp').assign(pcode=pcode)\n",
    "        v = v.reset_index()\n",
    "        v['temperature'] = trim_outlier(v['temperature'], threshold=3.0)\n",
    "        v= v[~v['temperature'].isnull()]\n",
    "        # Z-score normalize column 'temperature'\n",
    "        v['temperature'] = (v['temperature'] - v['temperature'].mean()) / v['temperature'].std()\n",
    "        temperature.append(v)\n",
    "\n",
    "    temperature = pd.concat(temperature, axis=0, ignore_index=True).set_index(\n",
    "                ['pcode', 'timestamp']\n",
    "            ) \n",
    "    \n",
    "    return temperature['temperature'].astype('float32')\n",
    "\n",
    "\n",
    "# RRI.csv\n",
    "def _proc_rri(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    RRI = []\n",
    "    for pcode in data.index.get_level_values('pcode').unique():\n",
    "        v = data.loc[(pcode, ), :].sort_index(axis=0,level='timestamp').assign(pcode=pcode)\n",
    "        v = v.reset_index()\n",
    "        v['interval'] = trim_outlier(v['interval'], threshold=3.0)\n",
    "        v= v[~v['interval'].isnull()]\n",
    "        # Z-score normalize column 'interval'\n",
    "        v['interval'] = (v['interval'] - v['interval'].mean()) / v['interval'].std()\n",
    "        RRI.append(v)\n",
    "\n",
    "    RRI = pd.concat(RRI, axis=0, ignore_index=True).set_index(\n",
    "                ['pcode', 'timestamp']\n",
    "            ) \n",
    "    return RRI['interval'].astype('float32')\n",
    "\n",
    "\n",
    "\n",
    "# HR.csv\n",
    "def _proc_hr(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    data['bpm'] = data.loc[(data['bpm'] >= 30) | (data['bpm'] <= 220), 'bpm']\n",
    "    data= data[~data['bpm'].isnull()]\n",
    "    HRT = []\n",
    "    for pcode in data.index.get_level_values('pcode').unique():\n",
    "        v = data.loc[(pcode, ), :].sort_index(axis=0,level='timestamp').assign(pcode=pcode)\n",
    "        v = v.reset_index()\n",
    "        v['bpm'] = trim_outlier(v['bpm'], threshold=3.0)\n",
    "        v= v[~v['bpm'].isnull()]\n",
    "        # Z-score normalize column 'bpm'\n",
    "        v['bpm'] = (v['bpm'] - v['bpm'].mean()) / v['bpm'].std()\n",
    "        HRT.append(v)\n",
    "\n",
    "    HRT = pd.concat(HRT, axis=0, ignore_index=True).set_index(\n",
    "                ['pcode', 'timestamp']\n",
    "            ) \n",
    "    return HRT['bpm'].astype('float32')\n",
    "    \n",
    "\n",
    "# EDA.csv\n",
    "def _proc_eda(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "\n",
    "    # Apply a median filter with a window size of window_size_sec seconds\n",
    "    window_size_sec = 5\n",
    "    window_size = window_size_sec * 2  # Multiply by the sampling frequency (2 Hz)\n",
    "\n",
    "   #Make the window size odd if it is even\n",
    "    if window_size % 2 == 0:\n",
    "        window_size += 1\n",
    "\n",
    "    data[\"conductance\"] = 1 / (data[\"resistance\"] / 1000) # divide by 1000 to convert kΩ to Ω\n",
    "    data['conductance'] =data.loc[(data['conductance'] >= 0.01) & (data['conductance'] <= 100), 'conductance']\n",
    "    data= data[~data['conductance'].isnull()]\n",
    "\n",
    "\n",
    "    eda = []\n",
    "    for pcode in data.index.get_level_values('pcode').unique():\n",
    "        v = data.loc[(pcode, ), :].sort_index(axis=0,level='timestamp').assign(pcode=pcode)\n",
    "        v = v.reset_index()\n",
    "\n",
    "        eda_data = v['conductance'].to_numpy()\n",
    "        eda_data = medfilt(eda_data, window_size)\n",
    "        # Reshape to 2D with a single column\n",
    "        eda_data = eda_data.reshape(-1, 1)\n",
    "#         eda_data = eda_data.reshape(-1)\n",
    "        # assuming your data is a numpy array with shape (n_samples, n_features)\n",
    "        scaler = MinMaxScaler()\n",
    "        eda_data_scaled = scaler.fit_transform(eda_data)\n",
    "        eda_data = scaler.inverse_transform(eda_data_scaled).reshape(-1)\n",
    "\n",
    "        v['conductance'] =eda_data\n",
    "        v= v[~v['conductance'].isnull()]\n",
    "\n",
    "        eda.append(v)\n",
    "\n",
    "    eda = pd.concat(eda, axis=0, ignore_index=True).set_index(\n",
    "                ['pcode', 'timestamp']\n",
    "            ) \n",
    "    \n",
    "    return eda['conductance'].astype('float32')\n",
    "\n",
    "\n",
    "# Distance.csv\n",
    "def _proc_distance(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    new_data = []\n",
    "\n",
    "    for pcode in data.index.get_level_values('pcode').unique():\n",
    "        sub = data.loc[(pcode, ), :].sort_index(\n",
    "            axis=0, level='timestamp'\n",
    "        ).assign(\n",
    "            distance=lambda x: x['totalDistance'] - x['totalDistance'].shift(1),\n",
    "            pcode=pcode\n",
    "        ).reset_index()\n",
    "\n",
    "        new_data.append(sub)\n",
    "\n",
    "    new_data = pd.concat(new_data, axis=0, ignore_index=True).set_index(\n",
    "        ['pcode', 'timestamp']\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'DST': new_data['distance'].dropna().astype('float32'),\n",
    "        # 'MOT': new_data['motionType'].astype('object'),\n",
    "        'PAC': new_data['pace'].astype('float32'),\n",
    "        'SPD': new_data['speed'].astype('float32')\n",
    "    }\n",
    "\n",
    "\n",
    "# Calorie.csv\n",
    "def _proc_calories(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    new_data = []\n",
    "\n",
    "    for pcode in data.index.get_level_values('pcode').unique():\n",
    "        sub = data.loc[(pcode, ), :].sort_index(\n",
    "            axis=0, level='timestamp'\n",
    "        ).assign(\n",
    "            calories=lambda x: x['totalCalories'] - x['totalCalories'].shift(1),\n",
    "            pcode=pcode\n",
    "        ).reset_index()\n",
    "\n",
    "        new_data.append(sub)\n",
    "\n",
    "    new_data = pd.concat(new_data, axis=0, ignore_index=True).set_index(\n",
    "        ['pcode', 'timestamp']\n",
    "    )\n",
    "\n",
    "    return new_data['calories'].dropna().astype('float32')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 14:57:24,911\tINFO worker.py:1664 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_process pid=19164)\u001b[0m [23-12-04 14:57:31] Begin to processing data: Distance\n",
      "\u001b[36m(_process pid=23568)\u001b[0m [23-12-04 14:57:31] Begin to processing data: Acceleration\n",
      "\u001b[36m(_process pid=29604)\u001b[0m [23-12-04 14:57:31] Begin to processing data: RRI\n",
      "\u001b[36m(_process pid=26000)\u001b[0m [23-12-04 14:57:31] Begin to processing data: AmbientLight\n",
      "\u001b[36m(_process pid=33840)\u001b[0m [23-12-04 14:57:31] Begin to processing data: StepCount\n",
      "\u001b[36m(_process pid=6860)\u001b[0m [23-12-04 14:57:31] Begin to processing data: SkinTemperature\n",
      "\u001b[36m(_process pid=12596)\u001b[0m [23-12-04 14:57:31] Begin to processing data: Calorie\n",
      "\u001b[36m(_process pid=29532)\u001b[0m [23-12-04 14:57:31] Begin to processing data: HR\n",
      "\u001b[36m(_process pid=17104)\u001b[0m [23-12-04 14:57:31] Begin to processing data: EDA\n",
      "\u001b[36m(_process pid=6860)\u001b[0m [23-12-04 14:57:32] Complete processing data: SkinTemperature\n",
      "\u001b[36m(_process pid=29532)\u001b[0m [23-12-04 14:58:12] Complete processing data: HR\n",
      "\u001b[36m(_process pid=33840)\u001b[0m [23-12-04 14:58:22] Complete processing data: StepCount\n",
      "\u001b[36m(_process pid=12596)\u001b[0m [23-12-04 14:58:22] Complete processing data: Calorie\n",
      "\u001b[36m(_process pid=26000)\u001b[0m [23-12-04 14:58:23] Complete processing data: AmbientLight\n",
      "\u001b[36m(_process pid=19164)\u001b[0m [23-12-04 14:58:28] Complete processing data: Distance\n",
      "\u001b[36m(_process pid=29604)\u001b[0m [23-12-04 14:58:30] Complete processing data: RRI\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\Drive\\Work\\Other computers\\My Laptop\\Homework\\Fall23\\AI502\\project\\ContrastiveLearningMobileStressDetection\\Preprocessing.ipynb Cell 17\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Drive/Work/Other%20computers/My%20Laptop/Homework/Fall23/AI502/project/ContrastiveLearningMobileStressDetection/Preprocessing.ipynb#X22sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     job \u001b[39m=\u001b[39m func(data_type)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Drive/Work/Other%20computers/My%20Laptop/Homework/Fall23/AI502/project/ContrastiveLearningMobileStressDetection/Preprocessing.ipynb#X22sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     jobs\u001b[39m.\u001b[39mappend(job)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Drive/Work/Other%20computers/My%20Laptop/Homework/Fall23/AI502/project/ContrastiveLearningMobileStressDetection/Preprocessing.ipynb#X22sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m jobs \u001b[39m=\u001b[39m ray\u001b[39m.\u001b[39mget(jobs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Drive/Work/Other%20computers/My%20Laptop/Homework/Fall23/AI502/project/ContrastiveLearningMobileStressDetection/Preprocessing.ipynb#X22sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m jobs \u001b[39m=\u001b[39m reduce(\u001b[39mlambda\u001b[39;00m a, b: {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39ma, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mb}, jobs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Drive/Work/Other%20computers/My%20Laptop/Homework/Fall23/AI502/project/ContrastiveLearningMobileStressDetection/Preprocessing.ipynb#X22sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m dump(jobs, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(PATH_INTERMEDIATE, \u001b[39m'\u001b[39m\u001b[39mproc.pkl\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[1;32md:\\Users\\Anas\\anaconda3\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py:24\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39m@wraps\u001b[39m(fn)\n\u001b[0;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mauto_init_wrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     23\u001b[0m     auto_init_ray()\n\u001b[1;32m---> 24\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Users\\Anas\\anaconda3\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[39mif\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[0;32m    102\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(ray, func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Users\\Anas\\anaconda3\\Lib\\site-packages\\ray\\_private\\worker.py:2557\u001b[0m, in \u001b[0;36mget\u001b[1;34m(object_refs, timeout)\u001b[0m\n\u001b[0;32m   2552\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2553\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mobject_refs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must either be an ObjectRef or a list of ObjectRefs.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2554\u001b[0m     )\n\u001b[0;32m   2556\u001b[0m \u001b[39m# TODO(ujvl): Consider how to allow user to retrieve the ready objects.\u001b[39;00m\n\u001b[1;32m-> 2557\u001b[0m values, debugger_breakpoint \u001b[39m=\u001b[39m worker\u001b[39m.\u001b[39mget_objects(object_refs, timeout\u001b[39m=\u001b[39mtimeout)\n\u001b[0;32m   2558\u001b[0m \u001b[39mfor\u001b[39;00m i, value \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(values):\n\u001b[0;32m   2559\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, RayError):\n",
      "File \u001b[1;32md:\\Users\\Anas\\anaconda3\\Lib\\site-packages\\ray\\_private\\worker.py:769\u001b[0m, in \u001b[0;36mWorker.get_objects\u001b[1;34m(self, object_refs, timeout)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    764\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAttempting to call `get` on the value \u001b[39m\u001b[39m{\u001b[39;00mobject_ref\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    765\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mwhich is not an ray.ObjectRef.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    766\u001b[0m         )\n\u001b[0;32m    768\u001b[0m timeout_ms \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(timeout \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m) \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m--> 769\u001b[0m data_metadata_pairs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcore_worker\u001b[39m.\u001b[39mget_objects(\n\u001b[0;32m    770\u001b[0m     object_refs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_task_id, timeout_ms\n\u001b[0;32m    771\u001b[0m )\n\u001b[0;32m    772\u001b[0m debugger_breakpoint \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    773\u001b[0m \u001b[39mfor\u001b[39;00m data, metadata \u001b[39min\u001b[39;00m data_metadata_pairs:\n",
      "File \u001b[1;32mpython\\ray\\_raylet.pyx:3211\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.get_objects\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpython\\ray\\_raylet.pyx:449\u001b[0m, in \u001b[0;36mray._raylet.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "from functools import reduce\n",
    "import warnings\n",
    "from pandas.errors import PerformanceWarning\n",
    "from Funcs.Utility import _load_data\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=PerformanceWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "FUNC_PROC = {\n",
    "    'Acceleration': _proc_acceleration,\n",
    "    'AmbientLight': _proc_ambient_light,\n",
    "    'Calorie': _proc_calories,\n",
    "    'Distance': _proc_distance,\n",
    "    'EDA': _proc_eda,\n",
    "    'HR': _proc_hr,\n",
    "    'RRI': _proc_rri,\n",
    "    'SkinTemperature': _proc_skin_temperature,\n",
    "    'StepCount': _proc_step_count\n",
    "}\n",
    "\n",
    "\n",
    "def _process(data_type: str):\n",
    "    log(f'Begin to processing data: {data_type}')\n",
    "    \n",
    "    abbrev = DATA_TYPES[data_type]\n",
    "    data_raw = _load_data(data_type)\n",
    "    data_proc = FUNC_PROC[data_type](data_raw)\n",
    "    result = dict()\n",
    "    \n",
    "    if type(data_proc) is dict:\n",
    "        for k, v in data_proc.items():\n",
    "            result[f'{abbrev}_{k}'] = v\n",
    "    else:\n",
    "        result[abbrev] = data_proc\n",
    "        \n",
    "    log(f'Complete processing data: {data_type}')\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "#with on_ray(num_cpus=6):\n",
    "with on_ray():\n",
    "    jobs = []\n",
    "    \n",
    "    func = ray.remote(_process).remote\n",
    "    \n",
    "    for data_type in DATA_TYPES:\n",
    "        job = func(data_type)\n",
    "        jobs.append(job)\n",
    "\n",
    "    jobs = ray.get(jobs)\n",
    "    jobs = reduce(lambda a, b: {**a, **b}, jobs)\n",
    "    dump(jobs, os.path.join(PATH_INTERMEDIATE, 'proc.pkl'))\n",
    "\n",
    "    del jobs\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sci-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
