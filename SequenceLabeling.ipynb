{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment the time series into 1 minute sequences for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Funcs.Utility import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Callable, Union, Tuple, List, Optional, Iterable\n",
    "from datetime import timedelta as td\n",
    "from scipy import stats\n",
    "import ray\n",
    "import warnings\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_na_check(_v):\n",
    "    _is_nan_inf = False\n",
    "    \n",
    "    try:\n",
    "        _is_nan_inf = np.isnan(_v) or np.isinf(_v)\n",
    "    except:\n",
    "        _is_nan_inf = False\n",
    "    \n",
    "    return _is_nan_inf or _v is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cloudpickle\n",
    "\n",
    "DATA = load(os.path.join(PATH_INTERMEDIATE, 'proc.pkl'))\n",
    "LABELS_PROC = pd.read_csv(os.path.join(PATH_INTERMEDIATE, 'proc', 'LABELS_PROC.csv'), index_col=['pcode','timestamp'],parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Attempting to acquire lock 140486769906064 on /tmp/ray/session_2023-12-05_19-51-17_743712_199065/ports_by_node.json.lock\n",
      "DEBUG:filelock:Lock 140486769906064 acquired on /tmp/ray/session_2023-12-05_19-51-17_743712_199065/ports_by_node.json.lock\n",
      "DEBUG:filelock:Attempting to release lock 140486769906064 on /tmp/ray/session_2023-12-05_19-51-17_743712_199065/ports_by_node.json.lock\n",
      "DEBUG:filelock:Lock 140486769906064 released on /tmp/ray/session_2023-12-05_19-51-17_743712_199065/ports_by_node.json.lock\n",
      "DEBUG:filelock:Attempting to acquire lock 140480173455248 on /tmp/ray/session_2023-12-05_19-51-17_743712_199065/ports_by_node.json.lock\n",
      "DEBUG:filelock:Lock 140480173455248 acquired on /tmp/ray/session_2023-12-05_19-51-17_743712_199065/ports_by_node.json.lock\n",
      "DEBUG:filelock:Attempting to release lock 140480173455248 on /tmp/ray/session_2023-12-05_19-51-17_743712_199065/ports_by_node.json.lock\n",
      "DEBUG:filelock:Lock 140480173455248 released on /tmp/ray/session_2023-12-05_19-51-17_743712_199065/ports_by_node.json.lock\n",
      "DEBUG:filelock:Attempting to acquire lock 140486770162992 on /tmp/ray/session_2023-12-05_19-51-17_743712_199065/ports_by_node.json.lock\n",
      "DEBUG:filelock:Lock 140486770162992 acquired on /tmp/ray/session_2023-12-05_19-51-17_743712_199065/ports_by_node.json.lock\n",
      "DEBUG:filelock:Attempting to release lock 140486770162992 on /tmp/ray/session_2023-12-05_19-51-17_743712_199065/ports_by_node.json.lock\n",
      "DEBUG:filelock:Lock 140486770162992 released on /tmp/ray/session_2023-12-05_19-51-17_743712_199065/ports_by_node.json.lock\n",
      "DEBUG:filelock:Attempting to acquire lock 140486122060576 on /tmp/ray/session_2023-12-05_19-51-17_743712_199065/ports_by_node.json.lock\n",
      "DEBUG:filelock:Lock 140486122060576 acquired on /tmp/ray/session_2023-12-05_19-51-17_743712_199065/ports_by_node.json.lock\n",
      "DEBUG:filelock:Attempting to release lock 140486122060576 on /tmp/ray/session_2023-12-05_19-51-17_743712_199065/ports_by_node.json.lock\n",
      "DEBUG:filelock:Lock 140486122060576 released on /tmp/ray/session_2023-12-05_19-51-17_743712_199065/ports_by_node.json.lock\n",
      "2023-12-05 19:51:19,791\tINFO worker.py:1612 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-05 19:51:20.369786 - Segmenting P01 data...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ray\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "RESAMPLE_S = {\n",
    "    'ACC_AXX': 0.25,\n",
    "    'ACC_AXY': 0.25,\n",
    "    'ACC_AXZ': 0.25,\n",
    "    'ACC_MAG': 0.25,\n",
    "    'EDA': 0.5,\n",
    "}\n",
    "\n",
    "@ray.remote\n",
    "def segment_sensor_data(pcode, sensor_type, sensor_data, label_data):\n",
    "    user_labels = label_data.loc[pcode]\n",
    "    if isinstance(user_labels, pd.Series):\n",
    "        user_labels = user_labels.to_frame().T\n",
    "\n",
    "    # Initialize empty DataFrames for labeled and unlabeled sequences\n",
    "    labeled_sequences_df = pd.DataFrame()\n",
    "    unlabeled_sequences_df = pd.DataFrame()\n",
    "\n",
    "    resampled_data = sensor_data.resample('T').asfreq()\n",
    "    if isinstance(resampled_data, pd.Series):\n",
    "        resampled_data = resampled_data.to_frame()\n",
    "\n",
    "    for time, row in resampled_data.iterrows():\n",
    "        sequence = {sensor_type: sensor_data.loc[time:time + pd.Timedelta(minutes=1)], 'pcode': pcode}\n",
    "\n",
    "        future_labels = user_labels[user_labels.index > time]\n",
    "        if not future_labels.empty:\n",
    "            time_differences = (future_labels.index - time).total_seconds()\n",
    "            abs_time_differences = abs(pd.Series(time_differences, index=future_labels.index))\n",
    "            nearest_future_time = abs_time_differences.idxmin()\n",
    "            label_row = future_labels.loc[nearest_future_time]\n",
    "\n",
    "            # Ensure duration is a valid number\n",
    "            duration = label_row['duration']\n",
    "            if pd.isna(duration) or not isinstance(duration, (int, float)):\n",
    "                duration = 1  # Default value or use another appropriate handling\n",
    "\n",
    "            overlapping_labels = user_labels[(user_labels.index >= time) & (user_labels.index - pd.Timedelta(minutes=duration) < time)]\n",
    "\n",
    "            if not overlapping_labels.empty:\n",
    "                label = overlapping_labels.iloc[-1]['stress_fixed']\n",
    "                sequence['label'] = label\n",
    "                labeled_sequence_df = pd.concat([pd.DataFrame(sequence)], ignore_index=True)\n",
    "                labeled_sequences_df = pd.concat([labeled_sequences_df, labeled_sequence_df], ignore_index=True)\n",
    "            else:\n",
    "                sequence['label'] = None\n",
    "                unlabeled_sequence_df = pd.concat([pd.DataFrame(sequence)], ignore_index=True)\n",
    "                unlabeled_sequences_df = pd.concat([unlabeled_sequences_df, unlabeled_sequence_df], ignore_index=True)\n",
    "        else:\n",
    "            sequence['label'] = None\n",
    "            unlabeled_sequence_df = pd.concat([pd.DataFrame(sequence)], ignore_index=True)\n",
    "            unlabeled_sequences_df = pd.concat([unlabeled_sequences_df, unlabeled_sequence_df], ignore_index=True)\n",
    "\n",
    "    return labeled_sequences_df, unlabeled_sequences_df\n",
    "\n",
    "with on_ray():\n",
    "    segmented_data = []\n",
    "    for pcode in LABELS_PROC.index.get_level_values('pcode').unique():\n",
    "        print(f\"{datetime.now()} - Segmenting {pcode} data...\")\n",
    "        for sensor_type, data in DATA.items():\n",
    "            if pcode in data.index.get_level_values('pcode'):\n",
    "                resample_interval = RESAMPLE_S.get(sensor_type, 1)\n",
    "                user_data = data.loc[pcode]\n",
    "                resampled_sensor_data = user_data.resample(f'{resample_interval}S').interpolate(method='linear').dropna()\n",
    "                segmented_data.append(segment_sensor_data.remote(pcode, sensor_type, resampled_sensor_data, LABELS_PROC))\n",
    "\n",
    "        results = ray.get(segmented_data)\n",
    "\n",
    "        print(f\"{datetime.now()} - Finished segmenting data.\")\n",
    "\n",
    "        # Aggregate DataFrames\n",
    "        labeled_df = pd.concat([item[0] for item in results], ignore_index=True)\n",
    "        unlabeled_df = pd.concat([item[1] for item in results], ignore_index=True)\n",
    "\n",
    "        print(f\"{datetime.now()} - Finished aggregating data.\")\n",
    "\n",
    "        labeled_df.to_csv(os.path.join(PATH_INTERMEDIATE, 'proc', 'labeled_sequences.csv'), index=False)\n",
    "        unlabeled_df.to_csv(os.path.join(PATH_INTERMEDIATE, 'proc', 'unlabeled_sequences.csv'), index=False)\n",
    "\n",
    "        print(f\"{datetime.now()} - Finished saving data.\")\n",
    "    results = ray.get(segmented_data)\n",
    "\n",
    "    print(\"Finished segmenting data.\")\n",
    "\n",
    "    # Aggregate DataFrames\n",
    "    labeled_df = pd.concat([item[0] for item in results], ignore_index=True)\n",
    "    unlabeled_df = pd.concat([item[1] for item in results], ignore_index=True)\n",
    "\n",
    "    print(\"Finished aggregating data.\")\n",
    "\n",
    "    labeled_df.to_csv(os.path.join(PATH_INTERMEDIATE, 'proc', 'labeled_sequences.csv'), index=False)\n",
    "    unlabeled_df.to_csv(os.path.join(PATH_INTERMEDIATE, 'proc', 'unlabeled_sequences.csv'), index=False)\n",
    "\n",
    "    print(\"Finished saving data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sci-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
